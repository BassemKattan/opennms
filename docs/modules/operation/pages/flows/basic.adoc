
[[flows-basic]]
= Start here: basic flows setup

This section describes how to get started with flows in a basic setup to collect, enrich (classify), persist, and visualize flows.

== Before you begin

Make sure you have configured your devices to send flows.
Refer to the manufacturer's documentation.
You will need to set up the flow receiver, which is OpenNMS {page-component-title}, and enable sending flows per interface on the firewall.

Set up an Elasticsearch cluster with the link:https://github.com/OpenNMS/elasticsearch-drift-plugin[Elasticsearch Drift plugin] installed on every Elasticsearch node.
The Drift plugin persists and queries flows that {page-component-title} collects.
The Drift version must match the targeted Elasticsearch version.

== Elasticsearch setup

Set the following environment variables in Elasticsearch:

[source, xml]
----

  es01:
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELASTICSEARCH_VERSION:-7.6.2}
    container_name: es01
    hostname: es01
    environment:
     TZ: ${TIMEZONE:-America/New_York}
     discovery.type: single-node
     node.name: es-node-01
    ports:
      - "9200:9200/tcp"
      - "9300:9300/tcp"
    volumes:
      - data-es01:/usr/share/elasticsearch/data
      - ./plugins:/usr/share/elasticsearch/plugins
    healthcheck:
      test: curl http://localhost:9200 >/dev/null; if [[ $$? == 52 ]]; then echo 0; else echo 1; fi
      interval: 30s
      timeout: 10s
      retries: 5
----

=== Tips

You may also want to set the following:

[source, xml]
----
ELASTIC_CONTAINER 	true
ES_JAVA_OPTS 	-Xms12g -Xmx12g <1>
PATH 	/usr/share/elasticsearch/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin <2>
search.max_buckets 	30000 <3>
----

<1> The RAM that JVM is allowed to consume.
<2> TBD
<3> Search bucket size.
You may want to increase the default value.

You may also want to create a job to clean the jobs so that the disk does not fill up, for example, keep X days of flows.
Filled disks are a challenging problem to address for non-Elasticsearch experts.
We recommend the Elasticsearch https://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.html[Curator tool] to do this.

[source, xml]
----

#!/bin/bash -eux

KEEP=15

docker run --rm -i \
    --entrypoint=/usr/bin/curator_cli bobrik/curator:5.8.1 \
    --host 10.10.3.218 \
    --timeout 600 \
    delete_indices \
    --ignore_empty_list \
    --filter_list '[{"filtertype":"pattern","kind":"prefix","value":"netflow"},{"filtertype":"count","count":'${KEEP}',"source":"creation_date"}]'

----

monitor the stack ... to get an alarm if these are down (see M. docs)

== Configure Elasticsearch persistence

From a Karaf shell on your {page-component-title} instance, update `$OPENNMS_HOME/etc/org.opennms.features.flows.persistence.elastic.cfg` to configure the flow persistence to use your Elasticsearch cluster:

[source, console]
----
$ ssh -p 8101 admin@localhost
...
admin@opennms()> config:edit org.opennms.features.flows.persistence.elastic
admin@opennms()> config:property-set elasticUrl http://elastic:9200
admin@opennms()> config:update
----

We also recommend setting the following:

[source, xml]
----
# ElasticSearch persistence configuration
elasticUrl = http://10.10.3.218:9200
connTimeout = 30000
readTimeout = 300000
settings.index.number_of_replicas = 0
settings.index.number_of_shards=1
settings.index.refresh_interval=10s
elasticIndexStrategy=daily
----

See <<elasticsearch/introduction.adoc#ga-elasticsearch-integration-configuration, General Elasticsearch Configuration>> for a complete set of options.

== Enable a protocol

By default ... 

Update `$OPENNMS_HOME/etc/telemetryd-configuration.xml` to enable one or more of the protocols you would like to handle.

In this example we enable the NetFlow v5 protocol, but you can repeat the same process for any of the other flow-related protocols.

[source, xml]
----
<listener name="Netflow-5-UDP-8877" class-name="org.opennms.netmgt.telemetry.listeners.UdpListener" enabled="true">
    <parameter key="port" value="8877"/>

    <parser name="Netflow-5-Parser" class-name="org.opennms.netmgt.telemetry.protocols.netflow.parser.Netflow5UdpParser" queue="Netflow-5" />
</listener>

<queue name="Netflow-5">
    <adapter name="Netflow-5-Adapter" class-name="org.opennms.netmgt.telemetry.protocols.netflow.adapter.netflow5.Netflow5Adapter" enabled="true">
    </adapter>
</queue>
----

Send a `reloadDaemonConfig` event via the CLI to apply the changes without restarting:

[source, console]
----
$OPENNMS_HOME/bin/send-event.pl -p 'daemonName Telemetryd' uei.opennms.org/internal/reloadDaemonConfig
----

This opens a UDP socket bound to `0.0.0.0:8877` to which NetFlow v5 messages are forwarded.

=== Set up multi-port listener
make sure you are using the Multi-port listener

edit `etc/telemetryd-configuration.xml` to specify multi-port listener.

== Link the web UI to Helm

To access flow-related graphs from the {page-component-title} web interface, you must configure a link to your instance of OpenNMS Helm.

----
$ ssh -p 8101 admin@localhost
...
admin@opennms()> config:edit org.opennms.netmgt.flows.rest
admin@opennms()> config:property-set flowGraphUrl 'http://grafana:3000/dashboard/flows?node=$nodeId&interface=$ifIndex'
admin@opennms()> config:update
----

NOTE: This URL can optionally point to other tools as well.
It supports placeholders for `$nodeId`, `$ifIndex`, `$start`, and `$end`.

Once configured, an icon will appear on the top-right corner of a resource graph for an SNMP interface if there is flow data for that interface.

== OpenNMS configuration

**etc/org.opennms.features.flows.persistence.elastic.cfg**



**etc/telemetryd-configuration.xml**

->
